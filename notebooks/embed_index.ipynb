{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2290afef",
   "metadata": {},
   "source": [
    "# Embed text chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1ec00",
   "metadata": {},
   "source": [
    "### Core imports and directory vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05483b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manth\\apps\\PhilGPT\\env\\.pixi\\envs\\default\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "data_dir = root_dir / 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334267a3",
   "metadata": {},
   "source": [
    "### Load data (text chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ce91a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33186/33186 [00:00<00:00, 15495065.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load chunks from jsonl file\n",
    "def load_chunks(file_path):\n",
    "    chunks = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            chunks.append(json.loads(line))\n",
    "    return chunks\n",
    "\n",
    "data = load_chunks(data_dir / 'transcript_chunks.jsonl')\n",
    "text = [item['text'] for item in tqdm(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474e45c",
   "metadata": {},
   "source": [
    "### Load model and embed text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd76e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached embeddings from c:\\Users\\manth\\apps\\PhilGPT\\data\\embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Embed text data\n",
    "# cached embeddings path\n",
    "embeddings_path = data_dir / 'embeddings.npy'\n",
    "\n",
    "if embeddings_path.exists():\n",
    "    print(f\"Loading cached embeddings from {embeddings_path}\")\n",
    "    embeddings = np.load(embeddings_path)\n",
    "else:\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = model.encode(text, batch_size=64, show_progress_bar=True, \n",
    "                              device=\"cuda\", normalize_embeddings=True)\n",
    "    np.save(embeddings_path, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76da4b8",
   "metadata": {},
   "source": [
    "## `FAISS` Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db446736",
   "metadata": {},
   "source": [
    "### Build and save `FAISS` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063aa770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert embeddings to float32\n",
    "embedding_matrix = np.array(embeddings).astype('float32')\n",
    "\n",
    "# use IndexFlatIP for cosine similarity\n",
    "index = faiss.IndexFlatIP(embedding_matrix.shape[1]) # dims = 384\n",
    "index.add(embedding_matrix) # add embeddings to index\n",
    "\n",
    "# Save the index\n",
    "save_path = data_dir / 'faiss_transcript_index.index'\n",
    "faiss.write_index(index, str(save_path)) #because faiss.write_index expects a string path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb74ef",
   "metadata": {},
   "source": [
    "### Store metadata for retrieval\n",
    "... and referencing?\n",
    "\n",
    "Another motivation to do this is **version control** because I will have a synced version of my index and metadata for consistent retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9699202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store metadata for retrieval\n",
    "metadata_dir = data_dir / 'faiss_transcript_metadata.json'\n",
    "with open(str(metadata_dir), 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9ef40",
   "metadata": {},
   "source": [
    "#### a very quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b40c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sts; they still strongly believe in the world that Marxism’s trying to bring about, but they’re highly critical of Marx for a few different reasons. Many critiques, but two of the major ones are that Marx doesn’t talk enough about the concept of personal liberty within his system and he certainly doesn’t do enough to consider the individual.  Remember, the thinkers of the Frankfurt School are living right around the same time as Husserl and Heidegger and Sartre and all these other thinkers that,\n",
      "-----\n",
      "e living in…if some of Marx’s predictions ultimately turned out to be…WRONG…maybe…Simone Weil might say…that has something to do with the fact that he didn’t REALLY understand what it FELT like to BE a worker. He certainly was a great economist. He certainly understood what it felt like to READ about being a worker…but what Marx DIDN’T know is what it felt like to CLOCK IN every day at four am with every JOINT in your BODY aching, just praying a forklift falls on top of you so you can at least f\n",
      "-----\n",
      " people that are exploited by that ruling class economically.  What Marx would want us to do here is try to apply Hegel’s dialectic to that process of economic change in the world. He says, think of the ruling class of people as the thesis and the exploited class of people as the antithesis. Well, eventually what always happens, he says, is the exploited class of people get tired of being exploited. There’s some sort of revolution that occurs. The ruling class is overthrown, and a new world emer\n",
      "-----\n",
      "uilding that society for. And he just didn’t THINK that sort of thing could be planned AHEAD of time.   Now what DID Marx say? Well he DID say that he saw that antagonism between classes in capitalism that we talked about before. He DID say that he thought inevitably, the working class would overthrow the ruling class. And what he recommended was that during that historical moment, as horrible as it was going to be, that the working class, after launching a revolution, while they’re REDESIGNING \n",
      "-----\n",
      "ition with them, the terrible effects on the environment because of the ceaseless desire to keep producing and consuming more and more beyond our means; the massive income disparity where the top 70 people in the world have more than the bottom 3 billion combined, many of them dying of starvation, dehydration, curable diseases. I think Marx would say, look at the problems we’re satisfied with contending with as an alternative.  Alright, this episode was a huge test for me. I hope it was as inter\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Load index\n",
    "index = faiss.read_index(str(save_path))\n",
    "\n",
    "# Embed query\n",
    "query = \"\"\n",
    "query_embedding = model.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "# Search\n",
    "D, I = index.search(query_embedding, k=10)  # D = similarity, I = indices\n",
    "\n",
    "# Get top results with basic deduplication\n",
    "seen_chunks = set()\n",
    "results = []\n",
    "for idx in I[0]:\n",
    "    chunk_id = data[idx][\"chunk_id\"]\n",
    "    if chunk_id not in seen_chunks:\n",
    "        seen_chunks.add(chunk_id)\n",
    "        results.append(idx)\n",
    "\n",
    "for unique_idx in results:\n",
    "    print(data[unique_idx]['text'])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c82fe4",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293ff7a",
   "metadata": {},
   "source": [
    "At this stage, I have\n",
    "- clean text chunks\n",
    "- embeddings\n",
    "- `faiss` index\n",
    "- metadata\n",
    "- tested retrieval with basic dedepulication\n",
    "\n",
    "So far: *retrieval → top-k results → console print.*\n",
    "\n",
    "Next: *retrieval → top-k chunks → format into prompt → send to LLM via Ollama → generate final answer*\n",
    "\n",
    "TODO: Consider using MMR (`max_marginal_relevance`) to retrieve diverse results from faiss index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622af13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a knowledgeable assistant who is interested in philosophy and about teaching \n",
    "others about philosophy. When asked questions, you answer them in a concise and informative manner,\n",
    "drawing from the provided context. If the context does not contain relevant information, you will say\n",
    "\"I don't know\" or \"I don't have enough information to answer that question.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8bc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(user_query):\n",
    "    # Load index\n",
    "    save_path = data_dir / 'faiss_transcript_index.index'\n",
    "    index = faiss.read_index(str(save_path))\n",
    "\n",
    "    # Embed query\n",
    "    query = user_query\n",
    "    query_embedding = model.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "    # Search\n",
    "    D, I = index.search(query_embedding, k=10)  # D = similarity, I = indices\n",
    "\n",
    "    # Get top results with basic deduplication\n",
    "    seen_chunks = set()\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        chunk_id = data[idx][\"chunk_id\"]\n",
    "        if chunk_id not in seen_chunks:\n",
    "            seen_chunks.add(chunk_id)\n",
    "            results.append(idx)\n",
    "\n",
    "    text_results = []\n",
    "    for unique_idx in results:\n",
    "        # print(data[unique_idx]['text'])\n",
    "        # print(\"-----\")\n",
    "        text_results.append(data[unique_idx]['text'])\n",
    "    \n",
    "    return \"\\n\".join(text_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "975fb900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your question: can you tell me a little bit more about the myth of sisyphus?\n",
      "PhilGPT's response:\n",
      "Okay, let’s delve a bit deeper into the myth of Sisyphus.\n",
      "\n",
      "Essentially, Sisyphus was a king of Corinth, and he was a particularly crafty and deceitful man. He wasn’t known for his piety or adherence to the gods. Instead, he was famous for tricking death itself!\n",
      "\n",
      "Here’s the core of the story:\n",
      "\n",
      "*   **His Deception:** Sisyphus tricked the god of the underworld, Hades, and his wife Persephone into eating pomegranate seeds. Under the terms of a pact, anyone who eats pomegranate seeds in the underworld is bound there for eternity. Sisyphus tricked Persephone into eating them, condemning her to spend half the year with Hades.\n",
      "\n",
      "*   **His Punishment:** As punishment for this deception, Sisyphus was condemned to eternally roll a massive boulder up a hill, only to have it roll back down every time he neared the top. This was a symbol of futile, repetitive labor – a task with no real purpose or outcome.\n",
      "\n",
      "*   **The Significance:** The myth isn't just about a king pushing a rock. It’s a powerful metaphor for the human condition – our awareness of the absurdity of existence, the inevitability of suffering, and the lack of inherent meaning in life. It highlights the contrast between our desires for purpose and the seemingly random, meaningless nature of the universe.\n",
      "\n",
      "It’s a story that has resonated through centuries, and it’s the foundation for much of Albert Camus’s philosophical ideas, particularly his concept of “absurdism.”\n",
      "\n",
      "Do you want me to elaborate on a specific aspect of the myth, such as its connection to Camus’s philosophy, or perhaps discuss the different versions of the story that exist?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "user_query = input(\"Ask your PhilGPT your question: \")\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': SYSTEM_PROMPT},\n",
    "        {'role': \"assistant\", 'content': retrieval(user_query)},\n",
    "        {'role': \"user\", 'content': user_query}\n",
    "    ])\n",
    "\n",
    "print(f\"Your question: {user_query}\")\n",
    "print(\"PhilGPT's response:\")\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
